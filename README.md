# PyTorch Learning Repository

This repository contains comprehensive PyTorch tutorials and quick reference materials for deep learning development.

## üìö Main Content

**[üìñ PyTorch Quick Reference Notebook](pytorch_quick_reference.ipynb)**

Essential operations for daily PyTorch development.

This section provides a comprehensive reference for common PyTorch tensor operations, from basic creation to advanced techniques.

- **Tensor Creation**: Basic tensors, random tensors, and data type conversion
- **Tensor Manipulation**: Reshaping, indexing, and slicing
- **Mathematical Operations**: Arithmetic, matrix operations, and statistics
- **Gradient Operations**: Automatic differentiation and gradient computation
- **Device Operations**: CPU/GPU management
- **Advanced Operations**: Concatenation, stacking, permutation, masking, gather and scatter, etc.
- **Memory Optimization**: In-place operations, memory sharing, and gradient checkpointing
- **Time Series Operations**: Rolling windows, moving averages, and sequence handling
- **Performance Tips**: Best practices for efficient PyTorch usage
- **Debugging**: Tensor inspection and common issues
- **Practical Examples**: Time series normalization, attention mechanisms, and efficient matrix operations
- **einops** for readable torch ops

Key highlights of advanced features:
1. Memory optimization techniques including gradient checkpointing
1. Efficient matrix operations for 2D tensors
1. Attention mechanism implementations with temperature scaling
1. Batch processing with automatic padding

Use these operations as building blocks for your PyTorch projects!

## üî¨ Additional Resources

- [PyTorch Official Documentation](https://pytorch.org/docs/stable/tensors.html)
- [PyTorch Tutorials](https://pytorch.org/tutorials/)
- [PyTorch Forums](https://discuss.pytorch.org/)
- einops for common DL patterns
    - https://github.com/arogozhnikov/einops/blob/main/docs/2-einops-for-deep-learning.ipynb
    - https://einops.rocks/pytorch-examples.html


## üìù License

This project is open source and available under the MIT License.
